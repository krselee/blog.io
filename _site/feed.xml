<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>KrseLee的博客</title>
    <description>Learning, Sharing, and Growing</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sat, 02 Sep 2017 23:34:48 +0800</pubDate>
    <lastBuildDate>Sat, 02 Sep 2017 23:34:48 +0800</lastBuildDate>
    <generator>Jekyll v3.5.1</generator>
    
      <item>
        <title>TensorFlow学习——用CNN训练机器识别信长和信喵</title>
        <description>&lt;p&gt;最近想搞个图片分类器，实现自己加载本地的图片进行训练，然后保存模型，另起一个程序加载模型，然后读入几张图片进行预测。回头盘点了下几个熟悉开源的DL工具，觉得做图片分类还是tensorflow比较方便，于是就找了点图片完成了这个模型，这里记录一下。&lt;/p&gt;

&lt;h2 id=&quot;一数据准备&quot;&gt;一.数据准备&lt;/h2&gt;
&lt;p&gt;用什么数据来构造分类器呢？记得前两年很喜欢玩《信长之野望14》，里面不是有很多人物头像吗？而且还分&lt;code class=&quot;highlighter-rouge&quot;&gt;信长之野望原版&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;喵之信长&lt;/code&gt;版，索性做个分类器识别是人头还是猫头好了。&lt;/p&gt;

&lt;p&gt;数据下载地址（百度云）：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;链接: https://pan.baidu.com/s/1slUDK0t 密码: vjv8&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里面将头像数据分别放在了两个目录下，&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nobunaga ：原版头像
nobunyaga ：喵版头像
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;我从他们里面分别把信长的头像取了出去不做训练，看看最后的模型是否能够认识他。&lt;/p&gt;

&lt;h2 id=&quot;二载入数据&quot;&gt;二.载入数据&lt;/h2&gt;
&lt;p&gt;首先，用什么方法读取图片呢？百度一下之后觉得PIL是比较方便的，于是用pip装了下PIL就可以使用了。在pycharm中新建一个工程，创建python脚本CnnClassify，第一部分代码编写如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# -*- coding: utf-8 -*-

from PIL import Image
import glob
import os
import tensorflow as tf
import numpy as np
import time

img_path = '../images/nobu/'
model_dir = &quot;./model/nobu/&quot;
model_name = &quot;nobunaga_model&quot;

# 将所有的图片resize成100*100
w = 100
h = 100
c = 3


# 读取图片
def read_img(path):
    cate = [path + x for x in os.listdir(path) if os.path.isdir(path + x)]
    imgs = []
    labels = []
    for idx, folder in enumerate(cate):
        for im in glob.glob(folder + '/*.jpg'):
            print('reading the images:%s' % (im))
            print('classify is %d:' % (idx))
            # 打开图片
            img = Image.open(im)
            img = img.resize((w,h))
            img = np.array(img)
            imgs.append(img)
            labels.append(idx)
    return np.asarray(imgs, np.float32), np.asarray(labels, np.int32)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这段代码主要做了几件事情：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;把相关的工具给引用进来&lt;/li&gt;
  &lt;li&gt;设置一些全局变量，比如输入图片的路径、模型输出的路径以及规定训练用的图片大小&lt;/li&gt;
  &lt;li&gt;定义一个函数read_img来读取数据集，给定一个图片根目录，会自动读取其每个子目录下的图片，并且不同子目录的图片对应的分类号不同&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在读取图片时进行了一些转化，比如将原始图片大小转为100*100，然后转成了一个&lt;code class=&quot;highlighter-rouge&quot;&gt;(100,100,3)&lt;/code&gt;的NpArray，再把这个NpArray加入倒一个List中去，作为数据集，结构就成了&lt;code class=&quot;highlighter-rouge&quot;&gt;[n,100,100,3]&lt;/code&gt;；同理，这样构造一个标签集合labels。&lt;/p&gt;

&lt;p&gt;接下来要对数据进行一个划分，分为训练集和验证集，先对这些图片的顺序进行shuffle（洗牌），然后按照一个比例划分。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;data, label = read_img(img_path)

# 打乱顺序
num_example = data.shape[0]
arr = np.arange(num_example)
np.random.shuffle(arr)
data = data[arr]
label = label[arr]

# 将所有数据分为训练集和验证集
ratio = 0.8
s = np.int(num_example * ratio)
x_train = data[:s]
y_train = label[:s]
x_val = data[s:]
y_val = label[s:]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;至此，载入数据的工作完成。&lt;/p&gt;

&lt;h2 id=&quot;三构建cnn模型&quot;&gt;三.构建CNN模型&lt;/h2&gt;
&lt;p&gt;做图片分类的首选是卷积神经网络（CNN），当然目前有很多优秀的CNN模型可以使用，我这里参考了博文 &lt;a href=&quot;http://www.cnblogs.com/denny402/p/6931338.html&quot;&gt;http://www.cnblogs.com/denny402/p/6931338.html&lt;/a&gt; 给出的模型，代码编写如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# -----------------构建网络----------------------
# 占位符
x = tf.placeholder(tf.float32, shape=[None, w, h, c], name='x')
y_ = tf.placeholder(tf.int32, shape=[None, ], name='y_')

# 第一个卷积层（100——&amp;gt;50)
conv1 = tf.layers.conv2d(
    inputs=x,
    filters=32,
    kernel_size=[5, 5],
    padding=&quot;same&quot;,
    activation=tf.nn.relu,
    kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

# 第二个卷积层(50-&amp;gt;25)
conv2 = tf.layers.conv2d(
    inputs=pool1,
    filters=64,
    kernel_size=[5, 5],
    padding=&quot;same&quot;,
    activation=tf.nn.relu,
    kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

# 第三个卷积层(25-&amp;gt;12)
conv3 = tf.layers.conv2d(
    inputs=pool2,
    filters=128,
    kernel_size=[3, 3],
    padding=&quot;same&quot;,
    activation=tf.nn.relu,
    kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)

# 第四个卷积层(12-&amp;gt;6)
conv4 = tf.layers.conv2d(
    inputs=pool3,
    filters=128,
    kernel_size=[3, 3],
    padding=&quot;same&quot;,
    activation=tf.nn.relu,
    kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)

re1 = tf.reshape(pool4, [-1, 6 * 6 * 128])

# 全连接层
dense1 = tf.layers.dense(inputs=re1,
                         units=1024,
                         activation=tf.nn.relu,
                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),
                         kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))
dense2 = tf.layers.dense(inputs=dense1,
                         units=512,
                         activation=tf.nn.relu,
                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),
                         kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))
logits = tf.layers.dense(inputs=dense2,
                         units=5,
                         activation=None,
                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),
                         kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))
# ---------------------------网络结束---------------------------

loss = tf.losses.sparse_softmax_cross_entropy(labels=y_, logits=logits)
train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)
correct_prediction = tf.equal(tf.cast(tf.argmax(logits, 1), tf.int32), y_)
acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这段代码构造了一个4层卷积+池化的CNN网络，然后用全连接层进行输出，这个全连接层包括两个隐层，用&lt;code class=&quot;highlighter-rouge&quot;&gt;ReLU&lt;/code&gt;作为激活函数，一个输出层。最后，定义了损失函数、优化器、正确率度量和ACC。
至此，CNN模型构建完毕。&lt;/p&gt;

&lt;h2 id=&quot;四训练模型保存&quot;&gt;四.训练模型，保存&lt;/h2&gt;
&lt;p&gt;首先，定义了一个函数来按批次取数据进行训练&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False):
    assert len(inputs) == len(targets)
    if shuffle:
        indices = np.arange(len(inputs))
        np.random.shuffle(indices)
    for start_idx in range(0, len(inputs) - batch_size + 1, batch_size):
        if shuffle:
            excerpt = indices[start_idx:start_idx + batch_size]
        else:
            excerpt = slice(start_idx, start_idx + batch_size)
        yield inputs[excerpt], targets[excerpt]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;接着，定义总共进行多少轮训练，以及每轮训练使用的数据量大小batch。我使用的数据集有近400张图片，训练集80%，这里40轮，每轮64张，总共2560，相当于被张图片拿来训练了7、8次左右。然后创建了一个长连接的InteractiveSession。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;n_epoch = 40
batch_size = 64
sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;接下来就是训练和保存模型了。这里创建一个保存器，定义最多保存3个模型，创建模型生成路径，然后进行迭代训练，训练时打印每一轮的训练误差、ACC以及验证误差、ACC。迭代40轮之后ACC已经达到0.9以上了，试过增加迭代轮数ACC可以接近1。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 保存模型
saver=tf.train.Saver(max_to_keep=3)
max_acc=0

if not os.path.exists(model_dir):
    os.mkdir(model_dir)

for epoch in range(n_epoch):
    start_time = time.time()
    print (&quot;step:\t%d&quot; % epoch)
    # training
    train_loss, train_acc, n_batch = 0, 0, 0
    for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True):
        _, err, ac = sess.run([train_op, loss, acc], feed_dict={x: x_train_a, y_: y_train_a})
        print x_train_a.shape
        train_loss += err;
        train_acc += ac;
        n_batch += 1
    print(&quot;   train loss: %f&quot; % (train_loss / n_batch))
    print(&quot;   train acc: %f&quot; % (train_acc / n_batch))

    # validation
    val_loss, val_acc, n_batch = 0, 0, 0
    for x_val_a, y_val_a in minibatches(x_val, y_val, batch_size, shuffle=False):
        err, ac = sess.run([loss, acc], feed_dict={x: x_val_a, y_: y_val_a})
        val_loss += err;
        val_acc += ac;
        n_batch += 1
    print(&quot;   validation loss: %f&quot; % (val_loss / n_batch))
    print(&quot;   validation acc: %f&quot; % (val_acc / n_batch))

    # 保存模型
    if val_acc &amp;gt; max_acc:
        max_acc = val_acc
        saver.save(sess, os.path.join(model_dir, model_name), global_step = epoch+ 1)
        print &quot;保存模型成功！&quot;

sess.close()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这里有个技巧是每轮迭代计算新的验证ACC是否大于历史最有ACC，如果大于则把模型保存下来，否则就不保存。因为前面设置了最多保留3个模型，因此训练完后保留了ACC最高的3个模型。&lt;/p&gt;

&lt;h2 id=&quot;五加载模型和预测&quot;&gt;五.加载模型和预测&lt;/h2&gt;
&lt;p&gt;新建一个CnnPredict的Python脚本，首先要把刚才定义的模型结构搬过来，因为代码太多，这里就省略了（如果有可以把结构也保存到模型的方法你可以告诉我，我试过不把模型搬过来Saver就会报错，说没有模型需要保存）。&lt;/p&gt;

&lt;p&gt;接着是把sess和saver都还原出来，然后使用latest_checkpoint在生成的一堆模型中去找最后一个生成的模型，进行还原。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())

saver = tf.train.Saver()

# Load model
model_file=tf.train.latest_checkpoint(model_dir)
saver.restore(sess, model_file)

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;接下来就要把之前被我拎出来的信长的头像拿来做预测了。这里需要构造跟之前训练一样的数据格式，不然会报格式不匹配的错误。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 加载信长头像，正确的分类是0
imgs = []
labels = []

img = Image.open(img_path + &quot;00034_00001.jpg&quot;)
img = img.resize((w, h))
img = np.array(img)
imgs.append(img)
labels.append(0)

imgs = np.asarray(imgs, np.float32)
labels = np.asarray(labels, np.float32)

ret = sess.run(y_, feed_dict={x: imgs, y_:labels})
print(&quot;计算模型结果成功！&quot;)
# 显示测试结果
print(&quot;预测结果:%d&quot; % ret)
print(&quot;实际结果:%d&quot; % 0)

# 加载信喵头像，正确的分类是1
imgs = []
labels = []

img = Image.open(img_path + &quot;00034_01904.jpg&quot;)
img = img.resize((w, h))
img = np.array(img)
imgs.append(img)
labels.append(1)

imgs = np.asarray(imgs, np.float32)
labels = np.asarray(labels, np.float32)

# 根据模型计算结果
ret = sess.run(y_, feed_dict={x: imgs, y_:labels})
print(&quot;计算模型结果成功！&quot;)
# 显示测试结果
print(&quot;预测结果:%d&quot; % ret)
print(&quot;实际结果:%d&quot; % 1)
sess.close()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;预测结果如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;计算模型结果成功！
预测结果:0
实际结果:0
计算模型结果成功！
预测结果:1
实际结果:1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;很高兴，我们的机器能够正确识别信长和信喵了。
&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/blog_img/nobunaga/00034_00001.jpg&quot; alt=&quot;织田信长&quot; /&gt;
织田信长
&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/blog_img/nobunaga/00034_01904.jpg&quot; alt=&quot;织田信喵&quot; /&gt;
织田信喵&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献：&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href=&quot;http://www.cnblogs.com/denny402/p/6931338.html&quot;&gt;tensorflow 1.0 学习：用CNN进行图像分类&lt;/a&gt;      &lt;br /&gt;
[2] &lt;a href=&quot;http://wustmeiming.github.io/2017/01/09/Tensorflow%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E4%BD%BF%E7%94%A8/&quot;&gt;Tensorflow模型保存与使用&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;完整代码&quot;&gt;完整代码&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/LeeKrSe/TensorFlowDemo/tree/master/nobunaga/ImageClassify&quot;&gt;见我的github&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Aug 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2017/08/06/Tensor%E5%AD%A6%E4%B9%A0-%E7%94%A8CNN%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E8%AF%86%E5%88%AB%E4%BF%A1%E9%95%BF%E5%92%8C%E4%BF%A1%E5%96%B5/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/06/Tensor%E5%AD%A6%E4%B9%A0-%E7%94%A8CNN%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E8%AF%86%E5%88%AB%E4%BF%A1%E9%95%BF%E5%92%8C%E4%BF%A1%E5%96%B5/</guid>
        
        <category>tech</category>
        
        
      </item>
    
      <item>
        <title>西北环游记</title>
        <description>&lt;h1 id=&quot;西北环游记&quot;&gt;西北环游记&lt;/h1&gt;
&lt;h2 id=&quot;写在前面&quot;&gt;写在前面&lt;/h2&gt;
&lt;p&gt;此次西北之行是我们实验室（浙江大学软件学院2015级S310室）的毕业旅行，全程人均约5000，其中从杭到兰州、兰州返程、兰州西宁往返约1300，在外游玩共15天，包车10天，15天花费约3700。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/content.png&quot; alt=&quot;路线&quot; title=&quot;路线图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;此次行程虽一波三折，但庆幸的是遇到了一位很好的司机师傅——季品师傅，尽心尽力带我们游遍了西北主要景点，旅途中还为我们省下了不小的开销，包车价格也十分划算。应季师傅的请求，忙里偷闲，断断续续一个月的时间写下此篇游记，一来是为了对他一路上的照顾表示感谢，二来希望更多的朋友能够选择他和他的车队，最重要的是为实验室的小伙伴留下一份珍贵的回忆。&lt;/p&gt;

&lt;p&gt;附季师傅联系方式：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;手机&lt;/td&gt;
        &lt;td&gt;13997072186&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;微信&lt;/td&gt;
        &lt;td&gt;jp13997072186&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;如果说有一场旅行是多年后回味依旧能陶醉其中的，那一定是怀着激动而复杂的心情，领略过各种奇异的景色，同某些重要的人一起走过的旅行，更确切的说，就是这次青甘环游之行。&lt;/p&gt;
&lt;h2 id=&quot;一-启程&quot;&gt;一.	启程&lt;/h2&gt;
&lt;p&gt;事情一开始并不是那么一帆风顺，确定要旅行的时候，离出发日已不足十五天了。实验室的伙伴们最开始想走川西香格里拉大环线，却发现那条路并没有想象中的那么轻松，而去东南亚的护照还有一半人没有办理。接着，叶总和大尸兄宣布不参加毕业旅行，学神为了女朋友也选择退出，尚广回家过端午一定要六月才启程，其他人六月中下旬也有自己的安排……种种原因，眼看计划就要泡汤，不知是谁放眼中国地图，用手在西北画了一个圈——青海、甘肃，一个时间充裕、路况安全、景点丰富、别具风格的线路。这个想法很快得到了众人的赞同，于是乎，订了杭州到兰州的火车，伴着隆隆的汽笛，我们的旅途就这样开始了。&lt;/p&gt;
&lt;h2 id=&quot;二-自驾还是包车&quot;&gt;二.	自驾还是包车&lt;/h2&gt;
&lt;p&gt;我已不是第一次前往大西北了，2015年同“小茶馆”的三个小伙伴游西安，至华山，再到西宁，游青海湖和茶卡盐湖，在火车站和三位驴友一起包了辆七座车，司机是回民，路上遇到堵车，茶卡返程已是晚上七点，想住宿，司机坚决地说明早走得多付一天的钱，而黑马河已经没有便宜的住宿；想返程，又得额外加1/4的钱走高。回到了西宁已是凌晨，住宿也是早已订空，在城里吃了羊肠面和羊肉串，七个人挤了间废了九牛二虎之力才找到的破旧旅馆的单间。或许是羊肠面不干净，加上晚上肚子着了凉，第二天犯了肠炎，还好同行的小伙伴细心照顾，最后发着烧拉着肚子回了重庆。
俗话说要“吃一堑长一智”，第二次来玩，如何避免被坑是我觉得最重要的问题。小伙伴们就自驾和包车讨论了很久，神州租车七座2.0T的SUV一天费用接近300，整个环线下来油费得3000出头，路况不熟也不知道跑得背多少罚单，前面有多少危险；跟好几个包车师傅聊下来10天价格都在7500-9000，纯玩，会轻松很多，最终大伙儿决定包车。
既然是包车，那师傅的选择就尤为关键了。首先我是不赞成选择回族师傅的，这倒不是什么歧视，而是饮食习惯的问题，包车几乎是要管司机的饮食的，如果10天下来全是清真，那估计都吃的想吐了；其次是安全考虑，同行的三个是妹子，因此我们考虑选择中年的师傅，一是他们对路途、景点比较熟悉，二是自己也为人父母，有一个幸福的家庭，不会跟我们学生太计较小事情，更不会心生什么歹意。
根据这些条件，大伙儿联系了不下十个师傅，最后层层筛选，选择了最符合条件的于师傅。于师傅也很爽快，给了我们一个十天很优惠的价格，说玩得不满意不收钱，最后一天结账就好。于是我们满心欢喜地在火车上吃起了零食玩起了UNO，只等到达目的地——兰州。&lt;/p&gt;
&lt;h2 id=&quot;三-兰州拉面的故乡&quot;&gt;三.	兰州，拉面的故乡&lt;/h2&gt;
&lt;p&gt;说到兰州，想必你的第一印象是遍地开花的“兰州拉面”了，火车上听一个在浙读研的兰州人说，兰州最有名的拉面在鸿宾楼，于是下了火车第一件事就是去尝尝这个“兰州第一面”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/03/lanzhou01.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;
十块钱一碗面，二十块钱一份套餐在沿海倒不算贵，但在兰州也就这儿能卖到这个价了吧。说实话，吃了这面觉得全国的兰州拉面在味道上都是正宗的，不同之处只在于配菜和辣度了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/03/lanzhou02.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;
鸿宾楼往北两公里，就是是黄河边，水车博览园。初中学地理，老师说黄河流经陕北黄土高原时，因水土流失携带了大量黄沙，所以中下游河水发黄，上游的水质则是清澈的。到了兰州发现并不是这么回事，即使还处于上游，这里的黄河水已经黄成了药汤。
在水车博览园问了妹子们一个很简单又好像不简单的问题——静水中的水车为什么会不停地转动。苾湲很自然地上了套，说因为水车中水的势能转为了动能，不断地把水往上送，也就不断地获得了势能。且不说这个能量如何转化，假设转化是可行的，这样不就相当于造出了永动机了吗？于是只能嘲讽一下她，说，水车一直在转，当然是电动的啦。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/03/lanzhou03.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;水车博览园&quot; /&gt;
在兰州同靖远过来的学霸同志汇合，此行的六人众就算是齐了。兰州火车站的安检特别的严格，妹子们在杭州屈臣氏高价买了防晒喷雾被告知不能带上去西宁的动车，仿佛一道晴天霹雳打在她们的头上，带了近两千公里的喷雾，最后只能哪儿来回哪儿去。&lt;/p&gt;
&lt;h2 id=&quot;四-西宁阴霾之地依旧充满变数&quot;&gt;四.	西宁，阴霾之地，依旧充满变数&lt;/h2&gt;
&lt;p&gt;动车在海拔2000米的青藏高原上飞驰，还有十分钟就到西宁站了，于师傅打来一个电话说自己突然有事接不了这单，交给了另外一个师傅。当听到这个消息时大家的表情都是懵的，为什么有事要换人不提前说，当我们要到站了才说？众人的第一反应都是被坑了，这里面有什么猫腻，但之前已经回绝了其他师傅，因此也只能先看看情况了。
来接车的师傅姓季，汉族人，四十来岁，典型的西北汉子，皮肤黝黑，高大微胖，一见面就送上了哈达表示欢迎。钱宝宝走在前面，也不推辞，直接就套在了脖子上，让众人都倒吸了一口气。为了搞清楚情况，苾湲继续跟于师傅电话沟通，我和学霸就上去和季师傅聊天。季师傅稍有腼腆，说自己是于师傅的徒弟，以前在西宁开出租，近年来旅游业发展旺盛，就跟着于师傅跑西北包车，接着我们又聊了聊路线，倒也听不出什么端倪。不过最后跟苾湲学霸商量，觉得因为突然换人，让我们的信任感一下跌入了谷底，暂时无法接受，需要晚上回酒店商量再决定，季师傅也表示理解，开车把我们送到了莫家街订的酒店。
这一晚是比较难熬的一晚，大家针对要不要坐季师傅的车讨论了好久，最后苾湲怕季师傅那边等久了，就直接回绝了。天色已晚，这一日是没法作出决定了，于是我们把行程推迟了一天，第二天一早又跟其他几个师傅联系了下，但其他师傅也不符合我们的条件。这时候于师傅又给我们来了电话，首先表明了不能亲自接单的歉意，然后说季师傅人看着可能有点粗，但是一个非常细心和热心的人，是他信得过的徒弟，如果路上有什么情况可以直接找他解决。
经过一晚的忙碌，大家对突然换人的做法已不是那么在意。所谓用人不疑，疑人不用，既然之前我们信任了于师傅，那么对于他推荐的人也应信任，季师傅在各方面还挺符合我们的要求，既然这样，又何必纠结呢。大家对此表示赞同，于是跟于师傅表达了我们的观点，确定了最终的方案，为了以防万一，我们还对电话录了音。就这样，怀着复杂的心情，我们的环游之旅开始了。&lt;/p&gt;
&lt;h2 id=&quot;五-青海湖梦幻般的湖&quot;&gt;五.	青海湖，梦幻般的湖&lt;/h2&gt;
&lt;p&gt;塔尔寺、拉脊山、青海湖是第一日的行程。&lt;/p&gt;

&lt;p&gt;塔尔寺，这座藏传佛教格鲁派的圣寺，其规模的宏大，可以和杭州的灵隐、镇江的金山相媲美，我们用了足足三个小时才游完整座寺庙。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/taersi01.jpeg&quot; alt=&quot;塔尔寺&amp;quot;&quot; title=&quot;塔尔寺&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/taersi02.jpg&quot; alt=&quot;塔尔寺&amp;quot;&quot; title=&quot;塔尔寺&quot; /&gt;&lt;/p&gt;

&lt;p&gt;拉脊山是环游的第一座雪山，同行的伙伴大多没上过海拔3000米以上的山，车才行至山脚，便激动不已，要求季师傅停车拍照。师傅看着她们有点惊讶，不过也没多说一句就停下车来，等一群人对着雪山一顿乱拍之后回到车上，师傅把我们拉到了海拔3800左右的观景台，此时众人才傻了眼，与面前的群山相比，之前看到的仅仅是冰山一角。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/lajishan01.jpg&quot; alt=&quot;拉脊山&quot; title=&quot;拉脊山&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/lajishan02.jpg&quot; alt=&quot;拉脊山&quot; title=&quot;拉脊山&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/lajishan03.jpg&quot; alt=&quot;拉脊山&quot; title=&quot;拉脊山&quot; /&gt;
在倒淌河镇用过午饭，迎来了今日的重头戏——青海湖。最早听说青海湖的美是在冯君莉的散文中，她将青海湖的湛蓝和质朴描绘得淋漓尽致；两年前来青海湖，远远地领略了油菜花和波澜壮阔的湖面，却没能近距离地与她接触，直到这次，才近距离地感受到她的粗旷和壮丽。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/daotanghe01.jpeg&quot; alt=&quot;倒淌河镇&quot; title=&quot;倒淌河镇&quot; /&gt;
季师傅带我们去了一个可以下到湖边的景区，他跟入口收费的人打了个招呼，就以一个极低的价格让我们六个人进了去。这里面朝大海，背对雪山，远眺青海湖，水与天碧蓝一色，辽阔无边；近看青海湖，云与浪交织翻涌，气势磅礴。倏尔风起，远浪奔袭而来，拍打在湖岸的碎石滩上，激起雪白的浪花，又渐渐退去了踪迹；俄儿风静，湖面波光粼粼，岸边被吹得不知所措的人儿又恢复了平静。湖边有牧民的牦牛、骏马，有装饰着五彩旗帜的堡垒、秋千，有写着“青海湖”大字的石碑。妹子们在湖边欢乐极了，不断地摆出各种姿势，季师傅也沉浸在给我们拍照的欢乐之中。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/qinghaihu03.jpg&quot; alt=&quot;青海湖&quot; title=&quot;青海湖&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/qinghaihu04.jpg&quot; alt=&quot;青海湖&quot; title=&quot;青海湖&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/qinghaihu05.jpg&quot; alt=&quot;青海湖&quot; title=&quot;青海湖&quot; /&gt;
从湖边出来，师傅又带我们到了一处高地，站在高处远眺青海湖，目之所及，整个湖面尽收眼底。藏人称青海湖为“海”，其实一点也不过分，若不知自己在何处，面对这辽阔无垠的水面，谁又会觉得这只是一汪湛蓝的湖泊呢？翻越国道的护栏，早已抑制不住激动心情的我们不自觉地在草原上狂奔起来，只为和这天，这地，这湖，这洁白的羊群融为一体。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/qinghaihu01.jpg&quot; alt=&quot;青海湖&quot; title=&quot;青海湖&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/qinghaihu02.jpg&quot; alt=&quot;青海湖&quot; title=&quot;青海湖&quot; /&gt;
日已偏西，我们踏上了前往第一日宿地——黑马河镇的行程，学霸用师傅的车载音响放起了《蓝莲花》，大家一路欢笑一路高歌，尽情享受这在路上的感觉。&lt;/p&gt;
&lt;h2 id=&quot;六-从天空之镜到青藏铁路的源头&quot;&gt;六.	从天空之镜到青藏铁路的源头&lt;/h2&gt;
&lt;p&gt;如果没机会去玻利维亚，那么可以到茶卡盐湖一览“天空之镜”的盛景，当然这是茶卡人为了吸引游客做的广告，想要看到“天空之镜”还需要一个极好的天气。&lt;/p&gt;

&lt;p&gt;在黑马河看过日出，翻过橡皮山，便是茶卡境内。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/05/richu01.jpeg&quot; alt=&quot;黑马河&quot; title=&quot;黑马河日出&quot; /&gt;
两年前到茶卡盐湖，景区还极为混乱，印象最深的是买了门票却根本没有检票，游玩出来，同行的小哥以半价将票卖给了别人，后来我们拿着这钱在西宁吃了终生难忘的羊肠面。这次到茶卡完全变了样，听说是浙江的老板来投资建设，整个景区变得高大上起来，浙江人来旅游还能免门票，作为温州富商的同胞，尚广不禁得意起来。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/06/chaka01.jpg&quot; alt=&quot;茶卡盐湖&quot; title=&quot;茶卡盐湖&quot; /&gt;
茶卡盐湖景区分两大板块，一是湖边的盐塑，完全用湖中采的盐堆砌雕刻的塑像，如西王母、成吉思汗；二是通向盐湖深处的火车道，道旁设有下水点，可以走进湖中和水天融为一体。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/06/chaka02.jpg&quot; alt=&quot;茶卡盐湖&quot; title=&quot;茶卡盐湖&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/06/chaka03.jpg&quot; alt=&quot;茶卡盐湖&quot; title=&quot;茶卡盐湖&quot; /&gt;
也许是运气不好，两次到盐湖都是阴天，天上的云倒映在湖中是灰蒙蒙的一片。虽然景色不美，但是风很大呀，走到湖中心，狂风呼啸，吹得众人抬不起头。我们在景区行走了三个小时，被吹了三个小时，大家着衣也比较单薄，最后感慨：被吹成了傻逼。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/06/chaka04.jpeg&quot; alt=&quot;茶卡盐湖&quot; title=&quot;茶卡盐湖&quot; /&gt;
从盐湖出来用过了午饭，师傅开车上了高速，大家迷迷糊糊地睡着了，不知走了多久，到了德令哈，沿途看到了大片的防风林。车上时间较长，大家便开始吃起了东西，这时候就到了我表演削梨的时候了，也许在平时，削果皮不断还比较容易，但是在汽车后排狭小的空间里，汽车时而颠簸时而快慢，皮儿不断还真有点考验手艺，一口气削了好几个，成功的也只有一两个，不过看着大伙儿啃着梨满足的表情还是蛮开心的。可能是长时间开车的缘故，季师傅也开始犯困了，时不时把手探出车窗外吹吹风，时不时用手拍拍自己的脑袋，大伙儿也有点担心。还好不一会儿到了德令哈湖景区，我们决定下车玩一个小时，也给师傅点时间打个盹儿。
不出意外的是克鲁克湖也是浙江投资援建的，因此尚广又免了一单，美滋滋。这个湖与托素湖相邻，面积近50平方公里，景区倒是没啥特色，也不能说完全没特色，这里的蚊子特别的多，而且都是大个儿的蚊子，唯一庆幸的是它们不怎么咬人，否则就得不偿失了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/06/gonglu05.jpeg&quot; alt=&quot;柴达木公路&quot; title=&quot;柴达木公路&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/06/gonglu04.jpeg&quot; alt=&quot;柴达木公路&quot; title=&quot;柴达木公路&quot; /&gt;&lt;/p&gt;

&lt;p&gt;德令哈向西，就是是有聚宝盆美誉的柴达木盆地了，沿途经过壮丽的315国道，一边品尝季师傅给的高原酸奶，一边饱览柴达木盆地的丹霞地貌。远眺锡铁山，近看察尔汗林立的石化工厂，汽车在“万丈盐桥”上飞驰，最终在日落前来到了青藏铁路二期起点、青海第二大城市——格尔木。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/06/gonglu01.jpg&quot; alt=&quot;柴达木公路&quot; title=&quot;柴达木公路&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/06/gonglu02.jpg&quot; alt=&quot;柴达木公路&quot; title=&quot;柴达木公路&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这一日赶了有六百来公里路，车上学霸想上厕所，百里无人的高速上又难以找到，于是我说了句，忍一忍吧，这一忍，忍了近三百公里，等到达格尔木时，估摸着她已经到了轻轻一按就能放出水来的地步。接下来的一路上，我都被“忍一忍”几个字所吐槽。&lt;/p&gt;
&lt;h2 id=&quot;七-可可西里与高反的抗争&quot;&gt;七.	可可西里，与“高反”的抗争&lt;/h2&gt;
&lt;p&gt;从格尔木往南就是进藏的公路，路过昆仑山口后有一处路卡，对进藏车辆查得很严，大货车的长队排了好几公里，我也是头一次看到这么多的东风重卡和解放重卡。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/07/kunlun01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/07/kunlun03.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;
前往昆仑神泉的路上，我们在骆驼峰和一处供奉着西王母的神殿略作停留，然后才到达神泉。这是一眼四季不冻的冷泉，据说含有丰富的矿物质，但不知碍于什么，我们大家都只尝了一小口，现在想来着实可惜。季师傅在这里雅兴大发，不停地找角度为我们大家拍照，甚至为了拍女生们飞起来的照片趴在了地上，被大家称为敬业的摄影师。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/07/kunlun02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/07/kunlun04.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/07/shenquan01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/07/shenquan02.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/07/shenquan03.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;
再往南走，海拔开始不断的上升。沿途发现了成群的藏野驴、野骆驼、野狗，还有前往布达拉宫朝圣的藏民。到达可可西里自然保护区入口时，海拔已经4800米了，苾湲和学霸开始有了缺氧反应，加上温度接近零度，风还特别大，最后大家哆嗦得坐在塑像前合了个影。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/07/keke01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;
多年前有一部电影叫做《可可西里》，它给我印象最深刻的是盗猎者对藏羚羊无情的屠杀，还有与盗猎者殊死搏斗的巡山队员。如今的可可西里对藏羚羊的保护已经非常到位了，青藏铁路过境还想了各种方法为藏羚羊的迁徙留出了道路。然而不幸的是我们一路上没有看到藏羚羊，季师傅说现在正好是产仔的季节，加上可可西里十分广袤，沿着公路看到藏羚羊的几率不大。
约摸行了二三十公里，到达一处观景台，这里向南望去是雄伟的唐古拉山脉，向北望去是巍峨的昆仑山脉，而我们正好处在之间的大平原上。此时苾湲和学霸高原反应已经到了行动不便的地步了，于是稍作停留，我们便踏上了回程。回去的车上，我们三个男生挤到了车厢后排狭小的空间里，应该是车窗关着的缘故，回到可可西里入口的时候，季师傅也有些高反了，于是停下车来休息了十分钟。然而停在海拔4800米的地方，该高反的始终是高反的，在尚广的建议下季师傅强忍着高反点了火，往更低的地方开去。说也奇怪，到了海拔4600米左右以后，大家的高反症状都减弱了，随着海拔的继续下降，几位高反的同学又满血复活了。&lt;/p&gt;
&lt;h2 id=&quot;八-柴达木水上雅丹与魔鬼城&quot;&gt;八.	柴达木，水上雅丹与“魔鬼城”&lt;/h2&gt;
&lt;p&gt;如果说这一路有什么景色让人最为震撼，那就是青海的雅丹地貌。&lt;/p&gt;

&lt;p&gt;在格尔木用完早饭，就又开始了长途跋涉，从格尔木返回小柴旦立交两百公里，再向西两百公里，一路仍然是柴达木的戈壁风光，青色的柏油马路穿插在渺无人烟的金黄色的戈壁滩上，也是一道靓丽的风景。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shamo01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shamo02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shamo03.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shamo04.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shamo05.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;大约到了下午两点，我们来到了东台吉乃尔湖——水上雅丹。碧绿的湖水，风蚀的雅丹地貌，加上湛蓝的天空，色彩调和得恰到好处。登上一座雅丹山丘，远眺整个湖面，不由被大自然的鬼斧神工所震撼。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shuishang01.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shuishang02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shuishang05.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;学霸兴奋得有点忘我，刚换上了拖鞋就准备下水，结果一脚踩进了烂泥滩，弄得一脚泥巴。好不容易洗洗干净，换个地方又激动起来，结果没出意外又陷进了泥潭。众人排成一列，你拉我我拉你才把她和她的拖鞋拽了出来。季师傅掏出他的手机，开始给我们拍他的拿手绝活——空中飞人。在浅滩，在岸边，在崖壁上，大家都陶醉在这壮丽的景色之中。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shuishang03.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/shuishang04.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从水上雅丹出来，轻车熟路的季师傅带我们来到了另一处雅丹地貌——青海魔鬼城。没有湖泊，这里的雅丹显得格外阴森，像猫头鹰，像大猩猩，一个个山丘朝着相同的方向，仿佛一群正赴宴的魔鬼。往深处走了约五百米，季师傅说不能再走了，走远了，遇到了狼就危险了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/yadan01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/08/yadan02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;站在山头，顶天立地，是摄影的绝佳地点，在给众人拍完照后，学霸想让人给她拍几张“美美哒”，我便信誓旦旦地接过了手机，一阵啪啪啪后我们回到了车上，这时学霸才想起来看照片，不看不知道，一看吓一跳，在我的镜头下，水桶腰、小粗腿，应有尽有。&lt;/p&gt;

&lt;p&gt;沿西砂线继续行驶，看到了好多散养的骆驼，到了傍晚，到达了今日的终点——大柴旦镇，一座被旅游业拉起来的小镇。&lt;/p&gt;

&lt;h2 id=&quot;九-敦煌沙漠中的一片绿洲&quot;&gt;九.	敦煌，沙漠中的一片绿洲&lt;/h2&gt;

&lt;p&gt;早晨从大柴旦出发，来到镇外的一片盐湖，这湖中的盐已经完全析出结成了晶体，湖水也是蓝绿色，白白的盐，绿绿的水，以及身后连绵的祁连山脉，远景近景浑然一体。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/dachaidan01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从大柴旦往敦煌的路程有五六百公里，途经有“最美公路”之称的G3011，可惜天公不做美，常年缺水的大西北此时竟乌云密布，不多时便风雨大作。过当金山时，在山上飘起了鹅毛大雪，到了山脚又是瓢泼大雨，原本计划前往阿克塞石油小镇一睹九层妖塔取景地也只好作罢。来到阿克塞新城，由于常年缺水，城市并未规划排水系统，道路两旁的自行车道便成了小河。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/dangjinshan01.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;继续往北，雨终于停了下来，此时车窗两边的景色与青海境内全然不同，我们才意识到已经到了甘肃。甘肃西北是河西走廊的尽头，也是一个极为缺水的地区，有着敦煌“母亲河”之称的党河，在这个汛期却早已干涸。敦煌四周被沙漠环绕，长年以来依赖着党河和拉哈诺尔湖，这里的人们才代代繁衍下去。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/danghe01.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;傍晚，季师傅带我们来到了沙洲夜市，说要请我们吃一顿大餐。我们倒也不客气，牛肉串，大盘鸡，炕锅羊肉，土豆片（噢，每个菜里都是土豆，于是我们给羞涩的“温半城”尚广盛了好几碗土豆），大盘鸡里有一个鸡头，学霸问了句，鸡头能吃吗？众人摇摇头，我说，难道不能吃吗？于是碗里被众人强行塞了鸡头T_T，塞就塞吧，作为一个四川人，从小就没少吃过鸡头，在这里就趁机表演了一吧快速吃鸡头的“绝技”，看得其他人目瞪口呆。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/dunhuang01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;翌日，师傅一早将我们送到了莫高窟景区。莫高窟分为两个部分，第一部分是在售票处的影像陈列馆内看两部关于敦煌起源和莫高窟由来的纪录片，随后才乘景区巴士到莫高窟景区参观。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/mogaoku01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;莫高窟&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/mogaoku02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;敦煌莫高窟是古代中国佛教文化的瑰宝，历经南北朝、隋唐、五代十国、西夏、元朝近千年的积淀，形成了这座具有数百石窟、数千彩塑的“千佛洞”，为考古学界研究历代文化留下了宝贵的财富。导游带领我们观赏了九层塔和其他几个不同年代的洞窟，讲解了不同时期的塑像特点和礼佛文化，最后来到了窟群尽头的藏经洞。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/mogaoku03.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;高中时，语文老师讲余秋雨的《文化苦旅》，讲到《道士塔》，让我认识了一个有眼无珠，唯利是图，将国宝贱卖给洋人的道士——王圆箓。然而这次前来，讲解员讲到王道士时，说，其实最开始王道士发现藏经洞时也曾奔走当地各级衙门寻求保护，可是晚清官员昏朽至极，对其价值一无所知，还屡屡让王道士向其“献宝”。后来来了斯坦因，来了伯希，他们对藏经洞文物极为珍视，王道士才将文物出售，换得银两用来修缮其他洞窟。虽说王道士的善举远不足以弥补其犯下的错，然在那个动荡的岁月，“道士塔”的悲剧实乃时代的悲剧。&lt;/p&gt;

&lt;p&gt;时值六月，夏至未至，烈日却一点也不谦让，不像青海的高原气候，敦煌整个城市都暴露在炙热的骄阳下。从莫高窟出来的时候，学霸整个人仿佛要挂掉了，然而等坐上了大巴，回到了季师傅的车上，整个人又好了。中午回到城里，我们吃到了一路上最棒的一餐，靖远尕六羊羔肉，随后回了客栈休息，到晚上6点，向敦煌的最后一个景点——鸣沙山出发。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/mingshashan04.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/mingshashan02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;鸣沙山位于敦煌城南，离我们住宿的“月笼沙”客栈不远，骑骆驼、滑沙、登沙山、看日落、聆听月牙泉是主要的玩点。夏季的大西北白昼都很长，而敦煌是我们此行日落时间最晚的地方，一来是经度位于环线的最西边，日落最晚；二来是纬度位于环线的最北边，白昼最长。我们在山丘上等到了晚上10点才看到太阳一点点收拢它的光辉，沉没在无边的黑夜里。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/mingshashan01.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/09/mingshashan03.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从鸣沙山出来，季师傅带我们到月牙泉小镇吃夜宵，炒面片加红木烤肉，直到深夜才返回客栈，进入甜美的梦乡。&lt;/p&gt;
&lt;h2 id=&quot;十-跋涉河西走廊&quot;&gt;十.	跋涉河西走廊&lt;/h2&gt;
&lt;p&gt;说到河西走廊，我的第一印象是王维《使至塞上》中“大漠孤烟直，长河落日圆”的景象，王摩诘寥寥数句，勾勒出塞上壮阔雄奇的风光，把自己心中的凄凉融汇到这景色之中，成为千古流传的名篇。而河西走廊，这条狭长的通道千百年来都是连接中原和西域的命脉，也是无数文人墨客慨叹的地方。&lt;/p&gt;

&lt;p&gt;从敦煌出发，全程高速，不多时便到了以生产瓜果出名的瓜州，季师傅带我们来到高速路边一个开着十来家瓜果店的地方，这些店老板倒是蛮热情，吆喝着让我们去品尝，不过大家心里也有数，尝了不买肯定是不行的。所以最后我们只尝了一家的瓜果，然后稍微买了点特色干果和黄河蜜带了走，价格嘛，其实比城里要贵一点点。&lt;/p&gt;

&lt;p&gt;瓜洲向东南，是“春风不度玉门关”的玉门，再往东，就到了长城的起点——嘉峪关。嘉峪关号称“天下第一雄关”，由明代开国大将冯胜选址建关，西临玉门，背靠酒泉，是明代西北边陲的要塞，也是中国最大的关隘。&lt;/p&gt;

&lt;p&gt;到嘉峪关时正值正午，艳阳高照，大伙儿也是把自己围得严严实实。从正门进入景区，首先映入眼帘的是九眼泉湖，湖虽不大，却在炎炎夏日给人一种清凉之感。沿湖行约一公里，才到达主体景区。刚开始是一些石碑和介绍，讲述嘉峪关建关以来的风风雨雨，以及明长城的主要关口，再往前几百米，才到达嘉峪关下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/10/jiayuguan01.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/10/jiayuguan02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我到过险峻的剑门关，蜿蜒的八达岭，以及无数鲜为人知的关隘，它们往往依托地形，成为易守难攻的要冲，但是像嘉峪关这样暴露在平原之上的，还是头一回见到，这是一座以自身的雄伟铸就的天下名关。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/10/jiayuguan03.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/10/jiayuguan04.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从嘉峪关出来，驱车继续向东南，快6点时才到达今日最后一站——张掖七彩丹霞地质公园。由于正赶上世界文化遗产日，丹霞景区门票全免，非常合算。我们乘着景区大巴，在几个观景台间穿梭，这些观景台各有特色，其中最漂亮的，当属4号和五号，七彩的岩层，伴着七彩的热气球，别是一种风情。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/10/danxia01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/10/danxia02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/10/danxia03.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;天色渐晚，从景区出来回道酒店，大伙儿跟季师傅喝起了啤酒，途中我们嚷着让尚广和钱宝宝喝交杯，旁边一桌年过花甲的老人感慨说，年轻真好。用过晚饭，我们在客栈的顶层，看着星星，荡着秋千。&lt;/p&gt;

&lt;h2 id=&quot;十一-祁连高原北边的明珠&quot;&gt;十一.	祁连，高原北边的明珠&lt;/h2&gt;
&lt;p&gt;从张掖出发，往民乐县的国道绿荫葱葱，早晨的阳光透过树林间的缝隙，还有许多鸟儿在上面飞来飞去。过了民乐县不多久，就来到了今日第一站——扁都口。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/biandukou01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/biandukou02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;扁都口是进祁连山的山口，水草丰茂，雪山连绵。再往山中行走，则是一片大峡谷，两侧皆是绝壁，峡间淌一河流，险要之处，颇有一夫当关，万夫莫开之势。&lt;/p&gt;

&lt;p&gt;过扁都峡谷，便是峨堡镇，此时海拔已高，方才在甘肃境内还是夏天模样，到此地众人早已是瑟瑟发抖，妹子们刚一下车就赶紧躲进一家拉面店，吃过午饭，在车里穿好秋裤外套，我们才继续出发。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/qilian03.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从峨堡向西北，过阿柔大寺，一路上皆是辽阔的祁连草原。洁白的羊群，黝黑的牛群，在这里比比皆是。小皮同志在这里异常的兴奋，不断地幻想着要去捉一只小羊抱回车里。季师傅选了处风景较好的地段停了车，又开始给我们拍“空中飞人”了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/qilian01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/qilian02.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;快到傍晚时，我们到达了祁连县，这时天空下起了中雨，让我们不得不取消了去卓尔山的计划。到宾馆稍作歇息，出门用过晚饭，我们来到祁连县的瑞士小镇。这里的建筑很有中欧气息，街道中央还有各种凸显异域风情的雕塑。穿过小镇是湍急的黑河，河上有一座廊桥，穿过廊桥又是一片郁郁的林荫。暮色，霞光，雪山，流水，构成了祁连这幅美丽的画卷，驻足仰望，轻倚栏杆，静静的聆听小城美丽的夜晚。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/qilian04.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;祁连&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/qilian05.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/qilian06.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;翌日清晨，用过早点，又踏上了前往八一冰川的旅程。车从祁连县驶出，不远处是绮丽的黑河大峡谷，峡谷中道路蜿蜒，河流迎面向我们奔涌而来，河对岸是笔直的峭壁，却有不少不屈的苍松在悬壁上傲然挺立。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/qilian07.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/qilian08.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;鸿宾楼&quot; /&gt;&lt;/p&gt;

&lt;p&gt;出大峡谷，到野牛沟，又是辽阔的祁连草原，不知开了多少里程，道路变成了狭窄的乡间小道，再往前，海拔越来越高。海拔慢慢上了4000，季师傅挺担心妹子们会不会又出现高原反应，到了冰川入口，她们却显得精神抖擞，到处跑着跟路边棉花一样的雪地合影留念。&lt;/p&gt;

&lt;p&gt;往冰川前行的道路盖满了积雪，前约摸行了一两公里，路上的积雪有些融化，行走艰难，我们六人排成长长一列，一个踩着一个脚印慢慢挪动。再往前，雪就积得挺深了。学霸像智障一样对着雪地“噗”的一下就坐了上去，等她站起来，地上出现了一个硕大的雪坑，我也没有闲着，从地上抱起一团积雪就向苾湲和小皮砸去，一砸不要紧，她俩像着了魔似的开始疯狂地反击，学霸见势也加入了战斗，几个人在海拔4600米的地方打起了雪仗。钱宝宝和优雅的尚广不肯帮忙，于是成了三打一的局面，突然，学霸抱起一团雪朝我走来，大约一米的距离使劲砸到了我头上，让我好久都没反应过来，只能申请“停战”。休息一会儿之后，又踏上前往冰川的行程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/bingchuan01.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;八一冰川&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/bingchuan03.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;八一冰川&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在高原上跋涉并不是一件容易的事，氧气、体力都消耗得很快，前面从冰川出来的游客看到我们，给我们打气说，不远了，再走二十分钟就到了。可是就这“二十分钟”路程，我们花了足足两倍时间。等我们到达冰川时，学霸已经不行了，三个女生也没啥拍照的力气了，只坐着来了几张自拍。“八一冰川”本身并没有给人壮丽之感，但往冰川路上跋涉的坚持充满了乐趣，最后我也不会像王安石那样“咎其欲出者”，“悔其随之而不得极夫游之乐也”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/bingchuan04.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;八一冰川&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/11/bingchuan05.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;八一冰川&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;十二-环游的终点&quot;&gt;十二.	环游的终点&lt;/h2&gt;
&lt;p&gt;时间总是过的飞快，越快乐的时光越如白驹过隙。十天的行程转眼已到最后，从祁连出来，过大冬树垭口，进入金银滩草原，一遍又一遍被神曲“天下最美”所洗脑。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/12/dadongshu.jpeg&quot; alt=&quot;兰州第一面&quot; title=&quot;大冬树垭口&quot; /&gt;&lt;/p&gt;

&lt;p&gt;大伙儿好像在前几天用光了所有的力气，一整天几乎都窝在车里不肯下去，再加上天气阴沉，雾气环绕，美丽的金银滩也用面纱遮住了她动人的脸庞。草原上田鼠、野兔、羔羊、牦牛依然随处可见，很快我们就路过了原子城，来到了环游最后一站，湟源县丹葛尔古城。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/LeeKrSe/TravelToNorthWest/master/photo/xibei/12/dangeer.jpg&quot; alt=&quot;兰州第一面&quot; title=&quot;丹葛尔古城&quot; /&gt;&lt;/p&gt;

&lt;p&gt;来的时候古城尚在修缮，只是稍微游玩了会儿。据说在清代，这座城池因为地处交通要道异常繁华，又“小北京”之称，而如今繁华落尽，只剩下了岁月的痕迹。在这里观看了酿醋工艺，苾湲“满意地”品尝了牛初乳制成的酸奶，被学霸好好地说教了一番，我们又坐上了车。稍微打了一个盹儿，就回到了西宁。季师傅把我们送到了莫家街的酒店，收拾好东西便道了别，他第二天又有几位甘南的客人接待。&lt;/p&gt;

&lt;p&gt;大伙儿拖着疲惫的身体在酒店睡到了晚上，第三次光顾了莫家街的靖远羊羔肉，到西宁最大的华润万家扫荡了一波特产，第二日又乘动车回到了兰州。在这里做完了学校要求的毕业体检，学霸乘大巴先回靖远的家里去了，而我们剩下的几个人晚上撸了城西的东北烤王，第二日也分别飞往重庆、杭州，这场长达十五天的毕业旅程也就画上圆满的句号。&lt;/p&gt;

</description>
        <pubDate>Sun, 23 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/travels/2017/07/23/%E8%A5%BF%E5%8C%97%E7%8E%AF%E6%B8%B8%E8%AE%B0/</link>
        <guid isPermaLink="true">http://localhost:4000/travels/2017/07/23/%E8%A5%BF%E5%8C%97%E7%8E%AF%E6%B8%B8%E8%AE%B0/</guid>
        
        <category>travel</category>
        
        
        <category>travels</category>
        
      </item>
    
      <item>
        <title>DL4J学习——用LSTM预测大盘</title>
        <description>&lt;p&gt;LSTM是递归神经网络（RNN）的一个变种，相较于RNN而言，解决了记忆消失的问题，用来处理序列问题是一个很好的选择。本文主要介绍如何使用DL4J中的LSTM来执行回归分析，如果只是想通过学习本例来预测股市的筒子，建议还是放弃吧^-^。如果不清楚RNN和LSTM，可以先阅读 LSTM和递归网络教程 以及 通过DL4J使用递归网络 ，特别是不熟悉RNN输入和预测方式的强烈建议先阅读这两个教程。如果不太会建立DL4J的工程，建议在其样例工程中进行本实验。&lt;/p&gt;

&lt;p&gt;言归正传，文本通过使用 LSTM对上证指数历史数据进行回归学习，并给出一个初始序列预测之后20天的大盘收盘价格来演示如何使用LSTM处理简单的序列回归问题。首先是准备数据，可以下载例子中我使用的数据集。那么接下来的问题就分成如下几步：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;读入训练数据，并处理成一个DataIterator；&lt;/li&gt;
  &lt;li&gt;构建一个LSTM的递归神经网络；&lt;/li&gt;
  &lt;li&gt;迭代训练，并输出预测结果；&lt;/li&gt;
  &lt;li&gt;调参和优化。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;一处理训练数据&quot;&gt;一.处理训练数据&lt;/h3&gt;
&lt;p&gt;我们的数据是上证指数每个交易日的基本数据，格式为：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;股票代码 日期开盘价 收盘价最高价  最低价成交量  成交额涨跌幅
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个文件中的数据是倒序的，也就是说新的数据在最前面，因此在读取数据时需要做一次倒转。我将读取文件的方法放在Dataiterator中。DL4J给出了序列数据处理的DataIterator，但是在本例中我们是自己实现一个DataIterator。代码如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;package edu.zju.cst.krselee.example.stock;

import org.deeplearning4j.datasets.iterator.DataSetIterator;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.dataset.DataSet;
import org.nd4j.linalg.dataset.api.DataSetPreProcessor;
import org.nd4j.linalg.factory.Nd4j;

import java.io.BufferedReader;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStreamReader;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.NoSuchElementException;

/**
 * Created by kexi.lkx on 2016/8/23.
 */
public class StockDataIterator  implements DataSetIterator {

    private static final int VECTOR_SIZE = 6;
    //每批次的训练数据组数
    private int batchNum;

    //每组训练数据长度(DailyData的个数)
    private int exampleLength;

    //数据集
    private List&amp;lt;DailyData&amp;gt; dataList;

    //存放剩余数据组的index信息
    private List&amp;lt;Integer&amp;gt; dataRecord;

    private double[] maxNum;
    /**
     * 构造方法
     * */
    public StockDataIterator(){
        dataRecord = new ArrayList&amp;lt;&amp;gt;();
    }

    /**
     * 加载数据并初始化
     * */
    public boolean loadData(String fileName, int batchNum, int exampleLength){
        this.batchNum = batchNum;
        this.exampleLength = exampleLength;
        maxNum = new double[6];
        //加载文件中的股票数据
        try {
            readDataFromFile(fileName);
        }catch (Exception e){
            e.printStackTrace();
            return false;
        }
        //重置训练批次列表
        resetDataRecord();
        return true;
    }

    /**
     * 重置训练批次列表
     * */
    private void resetDataRecord(){
        dataRecord.clear();
        int total = dataList.size()/exampleLength+1;
        for( int i=0; i&amp;lt;total; i++ ){
            dataRecord.add(i * exampleLength);
        }
    }

    /**
     * 从文件中读取股票数据
     * */
    public List&amp;lt;DailyData&amp;gt; readDataFromFile(String fileName) throws IOException{
        dataList = new ArrayList&amp;lt;&amp;gt;();
        FileInputStream fis = new FileInputStream(fileName);
        BufferedReader in = new BufferedReader(new InputStreamReader(fis,&quot;UTF-8&quot;));
        String line = in.readLine();
        for(int i=0;i&amp;lt;maxNum.length;i++){
            maxNum[i] = 0;
        }
        System.out.println(&quot;读取数据..&quot;);
        while(line!=null){
            String[] strArr = line.split(&quot;,&quot;);
            if(strArr.length&amp;gt;=7) {
                DailyData data = new DailyData();
                //获得最大值信息，用于归一化
                double[] nums = new double[6];
                for(int j=0;j&amp;lt;6;j++){
                    nums[j] = Double.valueOf(strArr[j+2]);
                    if( nums[j]&amp;gt;maxNum[j] ){
                        maxNum[j] = nums[j];
                    }
                }
                //构造data对象
                data.setOpenPrice(Double.valueOf(nums[0]));
                data.setCloseprice(Double.valueOf(nums[1]));
                data.setMaxPrice(Double.valueOf(nums[2]));
                data.setMinPrice(Double.valueOf(nums[3]));
                data.setTurnover(Double.valueOf(nums[4]));
                data.setVolume(Double.valueOf(nums[5]));
                dataList.add(data);

            }
            line = in.readLine();
        }
        in.close();
        fis.close();
        System.out.println(&quot;反转list...&quot;);
        Collections.reverse(dataList);
        return dataList;
    }

    public double[] getMaxArr(){
        return this.maxNum;
    }

    public void reset(){
        resetDataRecord();
    }

    public boolean hasNext(){
        return dataRecord.size() &amp;gt; 0;
    }

    public DataSet next(){
        return next(batchNum);
    }

    /**
     * 获得接下来一次的训练数据集
     * */
    public DataSet next(int num){
        if( dataRecord.size() &amp;lt;= 0 ) {
            throw new NoSuchElementException();
        }
        int actualBatchSize = Math.min(num, dataRecord.size());
        int actualLength = Math.min(exampleLength,dataList.size()-dataRecord.get(0)-1);
        INDArray input = Nd4j.create(new int[]{actualBatchSize,VECTOR_SIZE,actualLength}, 'f');
        INDArray label = Nd4j.create(new int[]{actualBatchSize,1,actualLength}, 'f');
        DailyData nextData = null,curData = null;
        //获取每批次的训练数据和标签数据
        for(int i=0;i&amp;lt;actualBatchSize;i++){
            int index = dataRecord.remove(0);
            int endIndex = Math.min(index+exampleLength,dataList.size()-1);
            curData = dataList.get(index);
            for(int j=index;j&amp;lt;endIndex;j++){
                //获取数据信息
                nextData = dataList.get(j+1);
                //构造训练向量
                int c = endIndex-j-1;
                input.putScalar(new int[]{i, 0, c}, curData.getOpenPrice()/maxNum[0]);
                input.putScalar(new int[]{i, 1, c}, curData.getCloseprice()/maxNum[1]);
                input.putScalar(new int[]{i, 2, c}, curData.getMaxPrice()/maxNum[2]);
                input.putScalar(new int[]{i, 3, c}, curData.getMinPrice()/maxNum[3]);
                input.putScalar(new int[]{i, 4, c}, curData.getTurnover()/maxNum[4]);
                input.putScalar(new int[]{i, 5, c}, curData.getVolume()/maxNum[5]);
                //构造label向量
                label.putScalar(new int[]{i, 0, c}, nextData.getCloseprice()/maxNum[1]);
                curData = nextData;
            }
            if(dataRecord.size()&amp;lt;=0) {
                break;
            }
        }

        return new DataSet(input, label);
    }

    public int batch() {
        return batchNum;
    }

    public int cursor() {
        return totalExamples() - dataRecord.size();
    }

    public int numExamples() {
        return totalExamples();
    }

    public void setPreProcessor(DataSetPreProcessor preProcessor) {
        throw new UnsupportedOperationException(&quot;Not implemented&quot;);
    }

    public int totalExamples() {
        return (dataList.size()) / exampleLength;
    }

    public int inputColumns() {
        return dataList.size();
    }

    public int totalOutcomes() {
        return 1;
    }

    @Override
    public List&amp;lt;String&amp;gt; getLabels() {
        throw new UnsupportedOperationException(&quot;Not implemented&quot;);
    }

    @Override
    public void remove() {
        throw new UnsupportedOperationException();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;StockDataIterator实现了DataIterator接口，于是需要实现几个必须的方法，例如hasNext、next、reset……用来进行每一批次DataSet的获取，loadData和readDataFromFile用来获取数据，并保存在一个DailyData类型的List中，每次调用next方法时，就会从List取出当前需要的数据，并构造成DataSet，返回给调用者。DailyData的实现如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;package edu.zju.cst.krselee.example.stock;

/**
 * Created by kexi.lkx on 2016/8/23.
 */
public class DailyData {

    //开盘价
    private double openPrice;
    //收盘价
    private double closeprice;
    //最高价
    private double maxPrice;
    //最低价
    private double minPrice;
    //成交量
    private double turnover;
    //成交额
    private double volume;

    public double getTurnover() {

        return turnover;
    }

    public double getVolume() {
        return volume;
    }

    public DailyData(){

    }

    public double getOpenPrice() {
        return openPrice;
    }

    public double getCloseprice() {
        return closeprice;
    }

    public double getMaxPrice() {
        return maxPrice;
    }

    public double getMinPrice() {
        return minPrice;
    }

    public void setOpenPrice(double openPrice) {
        this.openPrice = openPrice;
    }

    public void setCloseprice(double closeprice) {
        this.closeprice = closeprice;
    }

    public void setMaxPrice(double maxPrice) {
        this.maxPrice = maxPrice;
    }

    public void setMinPrice(double minPrice) {
        this.minPrice = minPrice;
    }

    public void setTurnover(double turnover) {
        this.turnover = turnover;
    }

    public void setVolume(double volume) {
        this.volume = volume;
    }

    @Override
    public String toString(){
        StringBuilder builder = new StringBuilder();
        builder.append(&quot;开盘价=&quot;+this.openPrice+&quot;, &quot;);
        builder.append(&quot;收盘价=&quot;+this.closeprice+&quot;, &quot;);
        builder.append(&quot;最高价=&quot;+this.maxPrice+&quot;, &quot;);
        builder.append(&quot;最低价=&quot;+this.minPrice+&quot;, &quot;);
        builder.append(&quot;成交量=&quot;+this.turnover+&quot;, &quot;);
        builder.append(&quot;成交额=&quot;+this.volume);
        return builder.toString();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;代码中对数据的各个维度进行了归一化处理，方法是记录每个维度的最大值，构造特征向量与标签时用原始数值除以最大值，得到0-1之间的数，归一化的好处在于使训练过程收敛变快。读者也可以试试不归一化的情况，比较两者的差别。&lt;/p&gt;

&lt;h3 id=&quot;二构建lstm网络&quot;&gt;二.构建LSTM网络&lt;/h3&gt;
&lt;p&gt;本例中我构造了一个两个隐含层的LSTM网络，隐含层激活函数是tanh，输出层使用identity函数来执行回归（如果是做多分类一般用softmax，做二分类可以用sigmoid）。输入单元数为6，因为单个向量是6维的（开盘价、收盘价、最高价、最低价、成交量、成交额）；输出单元数为1，用于预测第二天收盘价，代码如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    private static final int IN_NUM = 6;
    private static final int OUT_NUM = 1;
    private static final int Epochs = 100;

    private static final int lstmLayer1Size = 50;
    private static final int lstmLayer2Size = 100;

    public static MultiLayerNetwork getNetModel(int nIn,int nOut){
        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
            .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).iterations(1)
            .learningRate(0.1)
            .rmsDecay(0.5)
            .seed(12345)
            .regularization(true)
            .l2(0.001)
            .weightInit(WeightInit.XAVIER)
            .updater(Updater.RMSPROP)
            .list()
            .layer(0, new GravesLSTM.Builder().nIn(nIn).nOut(lstmLayer1Size)
                .activation(&quot;tanh&quot;).build())
            .layer(1, new GravesLSTM.Builder().nIn(lstmLayer1Size).nOut(lstmLayer2Size)
                .activation(&quot;tanh&quot;).build())
            .layer(2, new RnnOutputLayer.Builder(LossFunctions.LossFunction.MSE).activation(&quot;identity&quot;)
                .nIn(lstmLayer2Size).nOut(nOut).build())
            .pretrain(false).backprop(true)
            .build();

        MultiLayerNetwork net = new MultiLayerNetwork(conf);
        net.init();
        net.setListeners(new ScoreIterationListener(1));

        return net;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这段代码中有很多参数可以进行调整来寻找最优的拟合效果或调整训练速率，比如隐含层单元数目、激活函数、学习速率、正则化因子……构造好网络后加入一个ScoreIterationListener来监听每次迭代训练后的得分。&lt;/p&gt;

&lt;h3 id=&quot;三执行迭代训练&quot;&gt;三.执行迭代训练&lt;/h3&gt;
&lt;p&gt;第二部分里面我们设置了完整训练集的迭代次数Epochs为100，表示用整个数据集反复训练100次，训练部分代码如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; public static void train(MultiLayerNetwork net,StockDataIterator iterator){
        //迭代训练
        for(int i=0;i&amp;lt;Epochs;i++) {
            DataSet dataSet = null;
            while (iterator.hasNext()) {
                dataSet = iterator.next();
                net.fit(dataSet);
            }
            iterator.reset();
            System.out.println();
            System.out.println(&quot;=================&amp;gt;完成第&quot;+i+&quot;次完整训练&quot;);
            INDArray initArray = getInitArray(iterator);

            System.out.println(&quot;预测结果：&quot;);
            for(int j=0;j&amp;lt;20;j++) {
                INDArray output = net.rnnTimeStep(initArray);
                System.out.print(output.getDouble(0)*iterator.getMaxArr()[1]+&quot; &quot;);
            }
            System.out.println();
            net.rnnClearPreviousState();
        }
    }

    private static INDArray getInitArray(StockDataIterator iter){
        double[] maxNums = iter.getMaxArr();
        INDArray initArray = Nd4j.zeros(1, 6, 1);
        initArray.putScalar(new int[]{0,0,0}, 3433.85/maxNums[0]);
        initArray.putScalar(new int[]{0,1,0}, 3445.41/maxNums[1]);
        initArray.putScalar(new int[]{0,2,0}, 3327.81/maxNums[2]);
        initArray.putScalar(new int[]{0,3,0}, 3470.37/maxNums[3]);
        initArray.putScalar(new int[]{0,4,0}, 304197903.0/maxNums[4]);
        initArray.putScalar(new int[]{0,5,0}, 3.8750365e+11/maxNums[5]);
        return initArray;
    }
      每当进行一次完整集的训练之后，我们初始化了一个初始序列进行预测之后20个序列的输出。整个程序主函数如下：

    public static void main(String[] args) {
        String inputFile = StockRnnPredict.class.getClassLoader().getResource(&quot;stock/sh000001.csv&quot;).getPath();
        int batchSize = 1;
        int exampleLength = 30;
        //初始化深度神经网络
        StockDataIterator iterator = new StockDataIterator();
        iterator.loadData(inputFile,batchSize,exampleLength);

        MultiLayerNetwork net = getNetModel(IN_NUM,OUT_NUM);
        train(net, iterator);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;迭代100次后，得到的输出序列如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3489.9679512619973 3516.991701169014 3510.4443733012677 3490.410951650143 3476.138713735342 3469.275475754738 3466.278687063456 3464.9017547094822 3464.2161934530736 3463.8574357616903 3463.670068384409 3463.582194536925 3463.5545977914335 3463.5658543586733 3463.6010765206815 3463.650460170508 3463.7067430067063 3463.764115188122 3463.8196717941764 3463.8705079042916 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;四进一步优化&quot;&gt;四.进一步优化&lt;/h3&gt;
&lt;p&gt;本文主要介绍DL4J中的LSTM的使用方法，并不是真的说如此就能准确的预测大盘走势了（当然，网络是有可能真的学习到一些大盘走势特征的），想要做预测需要对本例进行许多调整，比如获取更全面的每日大盘信息，选取更多合适的维度来构建特征向量，当然也可以调整预测值（比如涨或跌，做回归的准确性比做二分类差多了，而且有比较好的指标可以衡量模型的好坏），确定目标后可以调整在第二部分提到的那些参数。&lt;/p&gt;

</description>
        <pubDate>Tue, 23 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2016/08/23/%E7%94%A8LSTM%E9%A2%84%E6%B5%8B%E5%A4%A7%E7%9B%98/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/08/23/%E7%94%A8LSTM%E9%A2%84%E6%B5%8B%E5%A4%A7%E7%9B%98/</guid>
        
        <category>tech</category>
        
        
      </item>
    
      <item>
        <title>Deeplearning4j入门——让计算机阅读《天龙八部》</title>
        <description>&lt;p&gt;很早在实验室就看见钱宝宝用Google的Word2Vector来跑《天龙八部》，找出与指定词最相关的几个词，最近正好学习新出的深度学习开源项目DeepLearning4J，于是就拿这个例子来练手吧。DL4J的详细用法请看 &lt;a href=&quot;http://deeplearning4j.org/quickstart.html&quot;&gt;DL4J快速入门&lt;/a&gt; 。     &lt;br /&gt;
DeepLearning4J的Example中自带了很多应用实例，Word2Vector也在其中，因此我的工作主要是以下几步：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;准备开发环境和原始数据&lt;/li&gt;
  &lt;li&gt;分词，格式转换&lt;/li&gt;
  &lt;li&gt;构建Word2Vector模型并训练&lt;/li&gt;
  &lt;li&gt;测试并输出&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;一准备开发环境和原始数据&quot;&gt;一．准备开发环境和原始数据&lt;/h2&gt;
&lt;p&gt;开发环境我使用的是IDEA（用eclipse也OK），JDK1.7，Maven3.3.1。
上武侠小说网下载一篇《天龙八部》，去掉文件首尾的不相关信息，重命名放到指定位置，OK。&lt;/p&gt;

&lt;h2 id=&quot;二分词格式转换&quot;&gt;二．分词、格式转换&lt;/h2&gt;
&lt;p&gt;我比较喜欢使用复旦NLP，一是用惯了熟练，二是使用起来也方便，Maven引用FNLP有一点小问题，用官方给的maven坐标不能，解决方法可以参考我&lt;a href=&quot;http://blog.csdn.net/a398942089/article/details/51152776&quot;&gt;以前的文章&lt;/a&gt;，这里不再赘述。
新建Java工程（或者直接使用DL4J-example工程），新建JavaClass，命名为FudanTokenizer：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;package edu.zju.cst.krselee.example.word2vector;  

/** 
 * Created by KrseLee on 16/7/20. 
 */  
  
import org.fnlp.nlp.cn.tag.CWSTagger;  
import org.fnlp.util.exception.LoadModelException;  
  
import java.io.IOException;  
import java.util.List;  
  
import org.fnlp.ml.types.Dictionary;  
import org.fnlp.nlp.corpus.StopWords;  

public class FudanTokenizer {  
    private CWSTagger tag;  
  
    private StopWords stopWords;  
  
    public FudanTokenizer() {  
        String path = this.getClass().getClassLoader().getResource(&quot;&quot;).getPath();  
        System.out.println(path);  
        try {  
            tag = new CWSTagger(path + &quot;models/seg.m&quot;);  
        } catch (LoadModelException e) {  
            e.printStackTrace();  
        }  
  
    }  
  
    public String processSentence(String context) {  
        String s = tag.tag(context);  
        return s;  
    }  
  
    public String processSentence(String sentence, boolean english) {  
        if (english) {  
            tag.setEnFilter(true);  
        }  
        return tag.tag(sentence);  
    }  
  
    public String processFile(String filename) {  
        String result = tag.tagFile(filename);  
  
        return result;  
    }  
  
    /** 
     * 设置分词词典 
     */  
    public boolean setDictionary() {  
        String dictPath = this.getClass().getClassLoader().getResource(&quot;models/dict.txt&quot;).getPath();  
  
        Dictionary dict = null;  
        try {  
            dict = new Dictionary(dictPath);  
        } catch (IOException e) {  
            return false;  
        }  
        tag.setDictionary(dict);  
        return true;  
    }  
  
    /** 
     * 去除停用词 
     */  
    public List&amp;lt;String&amp;gt; flitStopWords(String[] words) {  
        try {  
            List&amp;lt;String&amp;gt; baseWords = stopWords.phraseDel(words);  
            return baseWords;  
        } catch (Exception e) {  
            e.printStackTrace();  
            return null;  
        }  
    }  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;并将模型文件（可以从&lt;a href=&quot;https://github.com/FudanNLP/fnlp/releases&quot;&gt;FNLP的release页面&lt;/a&gt;下载）拷入到resources目录下。        &lt;br /&gt;
在maven的pom.xml里面添加FNLP的依赖：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;  
    &amp;lt;groupId&amp;gt;org.fnlp&amp;lt;/groupId&amp;gt;  
    &amp;lt;artifactId&amp;gt;fnlp-core&amp;lt;/artifactId&amp;gt;  
    &amp;lt;version&amp;gt;2.1-SNAPSHOT&amp;lt;/version&amp;gt;  
&amp;lt;/dependency&amp;gt;  
  
&amp;lt;dependency&amp;gt;  
    &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;  
    &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;  
    &amp;lt;version&amp;gt;4.11&amp;lt;/version&amp;gt;  
&amp;lt;/dependency&amp;gt;  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;等Maven把工程编译好，将之前下载的数据文件放到resources目录下，新建一个主方法或者单元测试来执行分词：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public void processFile() throws Exception{  
       String filePath = this.getClass().getClassLoader().getResource(&quot;text/tlbb.txt&quot;).getPath();  
       BufferedReader in = new BufferedReader(new FileReader(filePath));  
  
       File outfile = new File(&quot;/Users/KrseLee/dataset/tlbb_t.txt&quot;);  
       if (outfile.exists()) {  
           outfile.delete();  
       }  
       FileOutputStream fop = new FileOutputStream(outfile);  
  
       // 构建FileOutputStream对象,文件不存在会自动新建  
       String line = in.readLine();  
       OutputStreamWriter writer = new OutputStreamWriter(fop, &quot;UTF-8&quot;);  
       while(line!=null) {  
           line = tokenizer.processSentence(line);  
           writer.append(line);  
           line = in.readLine();  
       }  
       in.close();  
       writer.close(); // 关闭写入流,同时会把缓冲区内容写入文件  
       fop.close(); // 关闭输出流,释放系统资源  
   }  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;三构建word2vector模型并训练&quot;&gt;三．构建Word2Vector模型并训练&lt;/h2&gt;
&lt;p&gt;引入DeepLearning4J的依赖包，新建Java Class ZhWord2Vector，代码如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;package edu.zju.cst.krselee.example.word2vector;  
  
import org.canova.api.util.ClassPathResource;  
import org.deeplearning4j.models.embeddings.loader.WordVectorSerializer;  
import org.deeplearning4j.models.word2vec.Word2Vec;  
import org.deeplearning4j.text.sentenceiterator.BasicLineIterator;  
import org.deeplearning4j.text.sentenceiterator.SentenceIterator;  
import org.slf4j.Logger;  
import org.slf4j.LoggerFactory;  
  
import java.util.Collection;  
  
/** 
 * Created by KrseLee on 16/7/20. 
 */  
public class ZhWord2Vector {  
    private static Logger log = LoggerFactory.getLogger(ZhWord2Vector.class);  
  
    public static void main(String[] args) throws Exception {  
  
        String filePath = new ClassPathResource(&quot;text/tlbb_t.txt&quot;).getFile().getAbsolutePath();  
  
        log.info(&quot;Load &amp;amp; Vectorize Sentences....&quot;);  
        // Strip white space before and after for each line  
        SentenceIterator iter = new BasicLineIterator(filePath);  
        // Split on white spaces in the line to get words  
  
        log.info(&quot;Building model....&quot;);  
        Word2Vec vec = new Word2Vec.Builder()  
            .minWordFrequency(5)  
            .iterations(1)  
            .layerSize(100)  
            .seed(42)  
            .windowSize(5)  
            .iterate(iter)  
            .build();  
  
        log.info(&quot;Fitting Word2Vec model....&quot;);  
        vec.fit();  
  
        log.info(&quot;Writing word vectors to text file....&quot;);  
  
        // Write word vectors  
        WordVectorSerializer.writeWordVectors(vec, &quot;tlbb_vectors.txt&quot;);  
        WordVectorSerializer.writeFullModel(vec,&quot;tlbb_model.txt&quot;);  
        String[] names = {&quot;萧峰&quot;,&quot;乔峰&quot;,&quot;段誉&quot;,&quot;虚竹&quot;,&quot;王语嫣&quot;,&quot;阿紫&quot;,&quot;阿朱&quot;,&quot;木婉清&quot;};  
        log.info(&quot;Closest Words:&quot;);  
  
        for(String name:names) {  
            System.out.println(name+&quot;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&quot;);  
            Collection&amp;lt;String&amp;gt; lst = vec.wordsNearest(name, 10);  
            System.out.println(lst);  
        }  
    }  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;将上一步得到的输出的分词后的小说文件拷贝到resources目录下，准备工作就完成了。&lt;/p&gt;

&lt;p&gt;##四．测试并输出
更改你想要查看的单词，运行程序，等待约4分钟，得到输出。不同的电脑因性能原因需要的时间不一致，深度网络的训练本身也是一件费时费力的事情。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;萧峰&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;  
[段誉, 叫骂, 一队队, 军官, 将, 狗子, 长矛, 指挥, 说, 传令]  
乔峰&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;  
[南, 大侠, 北, 大英雄, 四海, 厮, 听说, 奸谋, 威震, 全舵]  
段誉&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;  
[萧峰, 虚竹, 向, 玄渡, 等, 叫骂, 去, 辽兵, 一边, 城门]  
虚竹&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;  
[段誉, 向西, 萧峰, 向, 城门, 叫骂, 等, 辽兵, 玄鸣, 去]  
王语嫣&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;  
[巴天石, 钟灵, 木婉清, 草海, 朱丹臣, 老婆婆, 瘴气, 贾老者, 嗒嗒嗒, 途中]  
阿紫&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;  
[道, 穆贵妃, 抿嘴笑, 姊夫, 来, 叫, 又, 小嘴, 大人, 什么]  
阿朱&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;  
[深情, 想起, 换上, 父母, 想念, 恩情, 胡作非为, 迫, 情意, 永远]  
木婉清&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;  
[钟灵, 朱丹臣, 巴天石, 秦红棉, 范骅, 一行人, 王语嫣, 墙外, 阮星竹, 巴天]  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;好了，大功告成。&lt;/p&gt;
</description>
        <pubDate>Wed, 20 Jul 2016 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2016/07/20/DeepLearning4J%E5%85%A5%E9%97%A8-%E8%AE%A9%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%98%85%E8%AF%BB-%E5%A4%A9%E9%BE%99%E5%85%AB%E9%83%A8/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/07/20/DeepLearning4J%E5%85%A5%E9%97%A8-%E8%AE%A9%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%98%85%E8%AF%BB-%E5%A4%A9%E9%BE%99%E5%85%AB%E9%83%A8/</guid>
        
        
      </item>
    
      <item>
        <title>赣皖散游记</title>
        <description>&lt;h1 id=&quot;赣皖散游记&quot;&gt;赣皖散游记&lt;/h1&gt;

&lt;p&gt;甲午马年季夏，会逢公私之事，难以归蜀。余于沪一年，未尝远游，心念至此，方觉恨也。假此良机，且作一番出行，寻访向时憧憬之地，了余之愿也。&lt;/p&gt;

&lt;h2 id=&quot;豫章滕王阁游记&quot;&gt;豫章滕王阁游记&lt;/h2&gt;
&lt;p&gt;六月十九，天作大雨，余一行三人，披星而起。方至虹桥，黑云压城，水泄如帘。及登车，缘窗而望，流水汩汩，不知何人建瓴。车行六时，乃至豫章。&lt;/p&gt;

&lt;p&gt;倏尔已是廿一日，待公事毕，得空游于南昌，南昌之胜，首属滕王阁。滕王之名，源于唐滕王元婴，彼都督洪州，乃建此阁，以供消遣，至今已重修数次。才子王勃至此，为《秋日登洪府滕王阁饯别序》，此阁之名，乃闻于天下。&lt;/p&gt;

&lt;p&gt;余感怀王勃之才，其文赋底蕴，千年难有过者，后人至此，莫不以高山仰止之心，为景行行止之行。阁楼起于垒土之上，添以浓墨重彩，绿荫环绕，流水相映，屹立赣江之滨，巍峨雄峻；尽享日月之气，天宝物华，是勃谓曰“襟三江而带五湖，控蛮荆而引瓯越”也。&lt;/p&gt;

&lt;p&gt;登阁凭栏而望，赣江之景，尽收眼底。时过境迁，虽无“山原旷其盈视，川泽纡其骇瞩”之景，然江畔危楼林立，车水马龙，别有一番风味。登高远望，视野之空旷，及心灵之豁达，余常怀古人之心，临如此之景，文思岂能禁锢于彤管之间？勃虽英才，奈何天不假年，盛名虽负，却难拔擢于宦间。&lt;/p&gt;

&lt;p&gt;三尺微命，无路请缨，空怀其才，无处可施。自古良马云云，伯乐寥寥。孟子道，舜发于畎亩之中，傅说举于版筑之间，胶鬲举于鱼盐之中，管夷吾举于士，孙叔敖举于海，百里奚举于市。是故人显其才之前，皆埋没荒夷之中。勃虽仿毛遂，撰绝文而惊四座，然满座高朋，非平原使君，唯流芳名于百世，传丽文于千古也。&lt;/p&gt;

&lt;p&gt;同游者，日照李公新，温州吴正奔，甲午年七月初一记。&lt;/p&gt;

&lt;h2 id=&quot;寿春合肥游记&quot;&gt;寿春合肥游记&lt;/h2&gt;
&lt;p&gt;甲午马年大暑，返沪两日有余，待精力蓄足，独往皖府合肥访夏侯博延。车架溯流而上，历镇江，过金陵。至合肥已是午后，暑气正盛，博延亲趋相迎，尽览工大之景。傍与同乡会于巴渝酒馆，异乡逢故人，倍感亲切。&lt;/p&gt;

&lt;p&gt;翌日，天方肚白，与博延公造逍遥津，寻魏将张文远之迹。建安二十年，吴主孙权趁曹魏争汉中于刘备，亲陈十万大军来肥。时合肥守军仅七千，辽征敢死之士八百，直冲孙吴本营，大败吴军于逍遥津，权险丧命。此间一役，辽威名远扬，江东小儿闻之不敢夜啼。&lt;/p&gt;

&lt;p&gt;时隔千八百年，此间已无昔日硝烟，唯清风拂柳绿，明月暗花香。黄发垂髫，鹤发童颜，皆嬉戏于斯，俨然太平之景。过飞渡桥，经逍遥阁，行至深处，林木茂盛。林影间现一小亭，亭中矗一石碑，上书“魏故都亭侯张文远之墓”，为张辽亭也，亭后有一坟山，为张辽墓也。此间并无香火供奉，往来拜谒者亦屈指可数。昔访武侯祠，造姜维墓，皆香火鼎盛，一代名将，身后沦落至此，未免可悲也。&lt;/p&gt;

&lt;p&gt;出逍遥津，寻路数里，至李鸿章故居。鸿章号少荃，晚清重臣，太平天国之乱时得曾文正公赏识，赴淮建军，战功显赫，平步青云。后力主师夷长技，兴洋务，建水师，访列国，俨然中兴之象也。不料甲午一战，北洋水师全军覆没，李公赴日，虽据理力争，亦止割地赔款。又四年，慈禧竟向列国宣战，溃逃至陕，亦是李公留京，停战议和。庚子赔款四亿五千万，鸿章羞愤而辞世，大清国祚至此而竭也。其故居所陈，皆斯时之事。李公治朝，虽非克己为民，然其所为，确为中国现代之始也。不知李公者，皆嗤之中饱私囊，丧权辱国，然国运如此，康熙再世，恐亦难全矣。为官者，文能兴国，武能安邦者为上；克己奉公，两袖清风者为中；鱼肉百姓，唯利是图者为下，我观李公，三者俱全矣，其功过是非，如何道哉？&lt;/p&gt;

&lt;p&gt;出李府，辗转数里，至包公祠。包公名拯，北宋庐州人士，官至枢密副使，以清廉公正闻名于世，百姓盛誉其“青天”。&lt;/p&gt;

&lt;p&gt;祠园由清风阁、包公墓、浮庄及包公祠四处相聚而成，余与博延先至清风阁，此阁为后人修建，取“两袖清风”之二字为名，意扬包公清正之名。阁高六层，虽不及滕王阁之宏伟，然登阁远眺，亦觉天地顿开，恍然若仙也。出阁东行，乃是包公之墓。墓前矗一巍峨石碑，大书“宋枢密副使包孝肃公拯之墓”，四周清幽明净，胜张辽墓远矣。博延叹道“同处一城，何乃大相径庭？”转行数十步，探包公墓室，墓室阴森湿润，仅有灯数盏而已，室中存包公棺椁，隔窗而望，人不得近。出墓室，沿河而西，登浮庄，此间人迹罕至，枯叶盖地，无可观者也。&lt;/p&gt;

&lt;p&gt;再西行数百步，方至包公祠。此间慕名者甚多，香火鼎盛，祠堂供奉包公及随侍王朝、马汉、张龙、赵虎之像，祠外有一亭，为流芳亭，亭中一井，名曰“廉泉”，意立世为人，须清明若此泉也，相传贪恶官吏，旦饮此泉，必头痛欲裂。祠外另设一廊，为回澜轩，专陈包公之绩。而祠一头，则陈包公京剧蜡像之景，惟妙惟肖，栩栩如生。&lt;/p&gt;

&lt;p&gt;总揽庐州三杰，所司各异，文远以勇武保合肥不失，少荃以斡旋弃旧图新，包公以清名正天下之义。守一方者，威名虽赫，而仅为一时之势也；侍一朝者，功及一世，然千年之后，又足道哉？立一德者，虽隔万代，黎明百姓，莫不称颂其道也。故不知张辽者甚，毁誉少荃者参半，而无人不颂包公之廉也。甲午年七月初四记。&lt;/p&gt;

&lt;h2 id=&quot;淮南八公山游记&quot;&gt;淮南八公山游记&lt;/h2&gt;
&lt;p&gt;甲午马年夏，与博延同游寿春合肥故城，意犹未尽，乃北上趋淮，寻汉淮南王刘安之迹。安为汉高祖刘邦之孙，刘长之子，督寿春，历文、景、武三朝，广招宾客，为《淮南鸿烈》一书。宾客之中，以苏非、李尚、左吴、陈由、伍被、毛周、雷被、晋昌八人最盛，人称“八公”，传安与八公居城外山中修仙炼丹，后在此服药飞升，八公山以此得名。&lt;/p&gt;

&lt;p&gt;此山距城约数里，大道通畅。初入山，顿觉山风沁人心脾，神清气爽，好一修仙之地。入之弥深，此意愈浓。未几，见八公群像，安立其中，手捋其髯，神态自然。像旁石壁，刻“淮南子”三朱字。博延觅得曲径一，缘径徐前，至孙叔敖治水场。高处有一台，置石质司南，环二十四节气。再前数十步，有石雕数座，皆出《鸿烈》之文，凡一叶知秋、后羿射日、嫦娥奔月、女娲补天、削足适履种种也。继而前行，沿途皆书中石刻也，不可胜数，直至鸿烈书院。&lt;/p&gt;

&lt;p&gt;道尽于叉，直行有一石林，盖远古地貌也。石林之中，现一石阶，直通山顶。登梯数百步，林木葱葱，鸟啼虫鸣，不绝于耳。清风徐来，以致人不知倦也。石阶尽头为一开阔地，立一汉风庭院，白墙红瓦，盖淮南王宫也。宫中仅一正殿，奉刘安塑像，像前香火鼎盛，拜谒者络绎不绝。此间居道士数人，替人观像。殿后有一小门，门外小道不知何处。博延道：“此道弯曲甚矣，不知筑者何意。”余观之，道确曲折而上，似避何物。再上十步，方直通霄汉。登顶，见一八卦四方之坛，坛中有阴阳太极之图，盖语天人之所。此处山风愈烈，视野极旷，环顾四周，山势雄健，颇有八方来朝之象。昔人称安私结党羽，于山中密谋反叛之事，想必亦非无中生有。又闻昔秦王苻坚率军七十万伐晋，至八公山下，为晋人所破，晋军所指，风声鹤唳，草木皆兵。今观此山，正当要道，易守难攻，确乃兵家要地也。&lt;/p&gt;

&lt;p&gt;下坛，沿向时之途而返，出石林，至白塔寺，又折返岔路，寻忘情谷。此路久无人至，枯叶盖地，蚊虫甚多。至谷中，仅一亭，一涧而已。余与博延欲寻他景，山中折回数次，无果乃返。及出山，淝水之战旧址亦不得见，为一憾事也。&lt;/p&gt;

&lt;p&gt;八公飞升之言，虽只谣传，然八公山之灵，不亚蜀之青城。安居此良久，欲寻飞升之法，亦非怪诞之事也。而其所传《鸿烈》一书，惠及后世甚矣，若非诚心向道，又岂能为如此之作？甲午年七月初五记。&lt;/p&gt;
</description>
        <pubDate>Thu, 31 Jul 2014 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/travels/2014/07/31/%E8%B5%A3%E7%9A%96%E6%95%A3%E6%B8%B8%E8%AE%B0/</link>
        <guid isPermaLink="true">http://localhost:4000/travels/2014/07/31/%E8%B5%A3%E7%9A%96%E6%95%A3%E6%B8%B8%E8%AE%B0/</guid>
        
        <category>travel</category>
        
        
        <category>travels</category>
        
      </item>
    
      <item>
        <title>上海环游记</title>
        <description>&lt;h1 id=&quot;上海环游记&quot;&gt;上海环游记&lt;/h1&gt;

&lt;p&gt;癸巳蛇年八月十四，天高云淡，阳光怡人，会逢上海旅游盛典之末，念半月未能成行，甚是感慨，故与室友骑车出行。&lt;/p&gt;

&lt;p&gt;出正门，沿内环，过苏州河，风驰电掣，数月不曾如此，心中无限欢喜，数里长宁，一瞬而过。未几，便至徐汇。往日出行，每每安坐地铁之上，以致居魔都二年有余，所悉之处，唯寥寥数几，而此番行至徐汇，耳目一新。经体育馆，过宛平南，路转狭小，所经之地，满是上世纪建筑，再数里，便至南浦渡所。&lt;/p&gt;

&lt;p&gt;登船，倚栏而望，与岸上之景，迥乎不同。船行桥下，逆江而上，江风习习，心之豁达，始于眼中旷然。至南浦，建筑风格，又与浦西异也。&lt;/p&gt;

&lt;p&gt;沿龙阳路，寻杨高路，大道畅通，速之极也。忽现陆家嘴软件园，高楼林立，其风各异。再往前，便是世纪公园，此番前年方至，但如今凭双脚之力而至于此，心中之情，不言自喻。&lt;/p&gt;

&lt;p&gt;好景不长，未至江边，车脚脱落，每行百米，不得不下车整修，偌大浦东，难觅一店，哀哉，哀哉。杨高路尽头，便是卢浦渡所，此间渡船，略显奢华。渡江之时，身旁坐一同龄女子，不知其姓名，不知其来历，端庄典雅，小巧可爱，同船而渡，深感荣幸，正所谓若有所失，若有所得哉？&lt;/p&gt;

&lt;p&gt;方至浦西，便寻得店家，稍作修理，再开行程。缘杨树浦路，至北外滩，此间大楼虽不及浦东，然店面琳琅，人气旺盛。过外白渡，至外滩，三固道南京路不便行走，遂改走、行北京路。此间车辆川流不息，人群熙熙攘攘，便道难寻。约莫一时，方至新闸路，再行万航渡，穿越各大街小巷，终至中山公园。返校，酉时已去三四。&lt;/p&gt;

&lt;p&gt;此番骑行，内环之景，尽收眼底，往日不曾涉足之地，今亦一一涉猎。万千世界，非亲身涉足不可感受，非亲身经历不可洞悉。出门在外假车而行尚不可知，何况乎身居室内，不闻外界者云云？况年少轻狂，体力尚强，如此之行，若待多年之后，虽欲行，力不从也。&lt;/p&gt;

&lt;p&gt;同游者，松江沈公崮也，癸巳蛇年八月十五记。&lt;/p&gt;

</description>
        <pubDate>Thu, 19 Sep 2013 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/travels/2013/09/19/%E4%B8%8A%E6%B5%B7%E7%8E%AF%E6%B8%B8%E8%AE%B0/</link>
        <guid isPermaLink="true">http://localhost:4000/travels/2013/09/19/%E4%B8%8A%E6%B5%B7%E7%8E%AF%E6%B8%B8%E8%AE%B0/</guid>
        
        <category>travel</category>
        
        
        <category>travels</category>
        
      </item>
    
      <item>
        <title>浙东绍兴游记</title>
        <description>&lt;h1 id=&quot;浙东绍兴游记&quot;&gt;浙东绍兴游记&lt;/h1&gt;

&lt;p&gt;壬辰龙年，天朝国庆，长假八日，然阿柏误期，余不得出行，甚是惋惜。逢友人议游浙东绍兴，正合吾心。九月初六，余等五人朝发于上海虹桥，越嘉兴，过杭州，俄至绍兴。&lt;/p&gt;

&lt;p&gt;绍兴，古之会稽也，越王勾践为夫差所破匿于会稽山，事吴十年，卧薪尝胆，静待时局，终以三千越甲乘虚吞吴，争霸天下，会稽之名以此始得闻。人道“江东弟子多才俊”，千百年间，云集士人无数，及王羲之书《兰亭集序》，会稽山名闻于天下。&lt;/p&gt;

&lt;p&gt;既至绍兴，先访鲁迅。树人之名，如雷贯耳，绍兴为鲁迅故里，大街小巷，“鲁迅”二字，随处可见。&lt;/p&gt;

&lt;p&gt;树人祖父官居县令，家门兴旺，然至父辈，中道衰落。迅父早亡，不得已以典当度日。幼时师寿镜吾于三味书屋，何为三味？“读经味如稻粱，读史味如肴馔，读诸子百家味如醯醢”者也。余中学时览《从百草园到三味书屋》一文，印象颇深，百草园之所在，为鲁迅故居也。&lt;/p&gt;

&lt;p&gt;游罢鲁迅故居，余等趁兴访沈园，寻觅放翁遗风。沈园为私家园林，景色宜人，宋时池台极盛，名扬四海，然名存至今，只因绝唱《钗头凤》。知陆务观者，必知唐婉；知唐婉者，必因《钗头凤》。&lt;/p&gt;

&lt;p&gt;两情相悦，却不得白首，世事难违，佳人亦难聚。虽知天命，犹尽人事，多年之后，放翁返乡，时唐婉已作他人妻，只得遗《钗头凤·红酥手》一篇：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;红酥手，黄籘酒，满城春色宫墙柳。东风恶，欢情薄，一怀愁绪，几年离索。错，错，错！　　
春如旧，人空瘦，泪痕红浥鲛绡透。桃花落，闲池阁，山盟虽在，锦书难托。莫，莫，莫！　　
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;唐婉见之，感慨万千，一病不起，终因愁怨难解，郁郁而终！&lt;/p&gt;

&lt;p&gt;病中，唐婉提笔和《钗头凤·世情薄》词一厥：　　&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;世情薄，人情恶，雨送黄昏花易落。晓风乾，泪痕残，欲笺心事，独倚斜栏。难，难，难！　　
人成各，今非昨，病魂常似秋千索。角声寒，夜阑珊，怕人寻问，咽泪装欢。瞒，瞒，瞒！
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;词相印，心相印，虽为一世遗恨，终成千古佳话。&lt;/p&gt;

&lt;p&gt;出沈园，余等又往大禹陵而去。陵坐于会稽山麓，依山傍水，传为大禹葬地。入陵，少顷见山顶大禹铜像，高耸山头，岿然不动。至山麓，众人已乏，稍事休息，便得登山。陵山虽不高，未至山腰，众人早已气喘吁吁。余游历数载，青城、峨眉、黄山尚不在话下，百米会稽，自不便提，遂先行一步，至山腰笑看众人上山。良久，吾等尽皆至山顶，再观大禹之像，仿若天神。凭栏像台之上，俯察品类之盛，绍兴全城，尽收眼底，顿有一马平川，君临天下之感，想必勾践当年，亦立于会稽山头，百感交集，故能忍辱负重，大展宏图。山顶顿足，心旷神怡，思绪万千，或吴越之魂，尽在于此吧！&lt;/p&gt;

&lt;p&gt;日暮，归上海。&lt;/p&gt;

&lt;p&gt;同游者，盐城崔公昕，宁波张绪玉、范公季鸣，赖佳妮，壬辰年九月初七记。&lt;/p&gt;
</description>
        <pubDate>Sun, 21 Oct 2012 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/travels/2012/10/21/%E6%B5%99%E4%B8%9C%E7%BB%8D%E5%85%B4%E6%B8%B8%E8%AE%B0/</link>
        <guid isPermaLink="true">http://localhost:4000/travels/2012/10/21/%E6%B5%99%E4%B8%9C%E7%BB%8D%E5%85%B4%E6%B8%B8%E8%AE%B0/</guid>
        
        <category>travel</category>
        
        
        <category>travels</category>
        
      </item>
    
      <item>
        <title>寒食清明黄山行</title>
        <description>&lt;h1 id=&quot;寒食清明黄山行&quot;&gt;寒食清明黄山行&lt;/h1&gt;

&lt;p&gt;兹游黄山，可谓一波三折，向之意往苏杭，穿梭江南水乡之间，与司马震议，而终定黄山。玩水，陶冶情操，怡我之心；游山，尽释沉闷，快我之意。此游黄山，亦能远离城市，淡去喧嚣。&lt;/p&gt;

&lt;p&gt;清明时节，出行之人不可计数，大巴驶入沪杭高速，便开始漫长的堵车之旅。历近八时，跨三省之地，去平原而至丘陵，览浙村亦赏皖镇。&lt;/p&gt;

&lt;p&gt;至汤口，已是日落时分，司马震欲摸黑上山，无奈山路已封，又度上山无益，故寻得一酒家住下，待翌日辰时再做定夺。&lt;/p&gt;

&lt;p&gt;翌日，众人欲趁早上山，至山口车站，天地上下，唯人茫茫，上山之车，一票难求。又历二时，方上得一车，不多时，便可窥黄山一角，又一时，至后山脚云谷寺，登山之旅自此始也。&lt;/p&gt;

&lt;p&gt;初入山，与他山无异，山路为石梯，之侧树木，郁郁葱葱，上山之人，无不摩拳擦掌，欲一跃至山顶。至入胜亭，景色异转，流水潺潺，怪石嶙峋，去云谷寺已八里有余，路人或走或歇。山路多有旁道，虽险然近，下设电缆。我等为求爬山之感，拣而登之，而以油君最甚。&lt;/p&gt;

&lt;p&gt;过仙人指路，梦笔生花，经白鹤峰，山色宜人。已行十余里，日挂罥空中，路人长坐不行者，十之四五。余四人略有疲惫，幸与震早有准备，吃食塞满两包，故稍事休息，力又足矣。此时尚早，去光明顶仅四里，正午便至。&lt;/p&gt;

&lt;p&gt;光明顶乃黄山三大主峰之一，与炼丹峰相连，莲花、天都二峰相望。此峰不及莲花、天都，眺望四景，并无“一览众山小”之感，且白日高悬，云不能起，亦无身临仙境之意。山顶四周，人头攒动，喧闹甚矣。&lt;/p&gt;

&lt;p&gt;余悻悻欲返，未至莲花峰，而人已塞路，久久不得通。闻之，曰：“清明游山之人数万，而多聚此路。”有达官贵人者租滑竿而走旁路，而吾等只得随人海挪步，缓缓而前。后过百步云梯，下莲花峰，亦是如此。&lt;/p&gt;

&lt;p&gt;又三时有余，方至迎客松，此松年事已久，不得不以外力助之，而观松之人，少有察觉，所叹着，唯阿柏而已。&lt;/p&gt;

&lt;p&gt;过迎客松，登山之行已至尾声，吾与油相议，约尽吾二人全力，尽快下山，而阿柏与震在人群后，不得下，只得缓缓而行。约一时，与油于慈光阁相聚，度黄山之行，凡八时有余。&lt;/p&gt;

&lt;p&gt;古人云“黄山归来不看岳”，此番游玩，恨无此感。余于三年前游峨眉，记忆犹新，登黄山，自不能与之分离。峨眉之秀，之危，黄山远不能及，此一不如也；余登峨眉，往返两日有余，而黄山仅八时，登山之兴不得尽，此二不如也。峨眉金顶，日出、云海尽览，而黄山不得，此三不如也。登峨眉，游人依稀可数，故山景趋于原态，一路游玩随意，而黄山不得，此四不如也。有此四不如，兴不尽，怀未释，念霞客之言，颇为遗憾。&lt;/p&gt;

&lt;p&gt;游山玩水，在乎通天人之语，放浪形骸之外，超脱尘世，恍然惊梦，而非随波逐流，人云亦云，游转人群之中，忧几时得脱。山水之色，人岂能增其二一？兹游黄山，非恨山之不危，路之不遥，景之不丽，时之不宜，实乃不愿置身人海而后语“吾与天地相应”也。&lt;/p&gt;

&lt;p&gt;同游者，松江司马震，庐州阿柏，油三人。壬辰龙年四月初五记。&lt;/p&gt;
</description>
        <pubDate>Thu, 05 Apr 2012 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/travels/2012/04/05/%E5%AF%92%E9%A3%9F%E6%B8%85%E6%98%8E%E9%BB%84%E5%B1%B1%E8%A1%8C/</link>
        <guid isPermaLink="true">http://localhost:4000/travels/2012/04/05/%E5%AF%92%E9%A3%9F%E6%B8%85%E6%98%8E%E9%BB%84%E5%B1%B1%E8%A1%8C/</guid>
        
        <category>travel</category>
        
        
        <category>travels</category>
        
      </item>
    
  </channel>
</rss>
